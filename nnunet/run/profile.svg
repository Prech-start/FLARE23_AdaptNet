<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="410" onload="init(evt)" viewBox="0 0 1200 410" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:fg="http://github.com/jonhoo/inferno"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#matched { text-anchor:end; }
#search { text-anchor:end; opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[
        var nametype = 'Function:';
        var fontsize = 12;
        var fontwidth = 0.59;
        var xpad = 10;
        var inverted = true;
        var searchcolor = 'rgb(230,0,230)';
        var fluiddrawing = true;
        var truncate_text_right = false;
    ]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    total_samples = parseInt(frames.attributes.total_samples.value);
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[*|x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad;
            matchedtxt.attributes.x.value = svgWidth - xpad;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
            if (!isEdge) {
                svg.removeAttribute("viewBox");
            }
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes["fg:x"]) {
            var params = get_params()
            params.x = el.attributes["fg:x"].value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["fg:orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("fg:orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["fg:orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["fg:orig_" + attr].value;
    e.removeAttribute("fg:orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * parseInt(e.attributes["fg:x"].value) / total_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / total_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, zoomed_width_samples) {
    if (e.tagName == "text") {
        var parent_x = parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value);
        e.attributes.x.value = format_percent(parent_x + (100 * 3 / frames.attributes.width.value));
    } else if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * (parseInt(e.attributes["fg:x"].value) - x) / zoomed_width_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / zoomed_width_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, zoomed_width_samples);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseInt(attr["fg:w"].value);
    var xmin = parseInt(attr["fg:x"].value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseInt(a["fg:x"].value);
        var ew = parseInt(a["fg:w"].value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, width);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        // Skip over frames which are either not visible, or below the zoomed-to frame
        if (e.classList.contains("hide") || e.classList.contains("parent")) {
            continue;
        }
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseInt(rect.attributes["fg:w"].value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseInt(rect.attributes["fg:x"].value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    for (var k in keys) {
        var x = parseInt(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="410" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy record -o profile.svg -- python run_training.py 3d_fullres nnUNetTrainerV2 98 0 --npz</text><text id="details" x="10" y="40.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1190" y="24.00">Search</text><text id="matched" x="1190" y="399.00"> </text><svg id="frames" x="10" width="1180" total_samples="62954"><g><title>&lt;module&gt; (nnunet/training/model_restore.py:16) (103 samples, 0.16%)</title><rect x="0.0000%" y="260" width="0.1636%" height="15" fill="rgb(227,0,7)" fg:x="0" fg:w="103"/><text x="0.2500%" y="270.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (103 samples, 0.16%)</title><rect x="0.0000%" y="276" width="0.1636%" height="15" fill="rgb(217,0,24)" fg:x="0" fg:w="103"/><text x="0.2500%" y="286.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (103 samples, 0.16%)</title><rect x="0.0000%" y="292" width="0.1636%" height="15" fill="rgb(221,193,54)" fg:x="0" fg:w="103"/><text x="0.2500%" y="302.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (103 samples, 0.16%)</title><rect x="0.0000%" y="308" width="0.1636%" height="15" fill="rgb(248,212,6)" fg:x="0" fg:w="103"/><text x="0.2500%" y="318.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (103 samples, 0.16%)</title><rect x="0.0000%" y="324" width="0.1636%" height="15" fill="rgb(208,68,35)" fg:x="0" fg:w="103"/><text x="0.2500%" y="334.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (103 samples, 0.16%)</title><rect x="0.0000%" y="340" width="0.1636%" height="15" fill="rgb(232,128,0)" fg:x="0" fg:w="103"/><text x="0.2500%" y="350.50"></text></g><g><title>&lt;module&gt; (nnunet/run/run_training.py:18) (218 samples, 0.35%)</title><rect x="0.0000%" y="68" width="0.3463%" height="15" fill="rgb(207,160,47)" fg:x="0" fg:w="218"/><text x="0.2500%" y="78.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (218 samples, 0.35%)</title><rect x="0.0000%" y="84" width="0.3463%" height="15" fill="rgb(228,23,34)" fg:x="0" fg:w="218"/><text x="0.2500%" y="94.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (218 samples, 0.35%)</title><rect x="0.0000%" y="100" width="0.3463%" height="15" fill="rgb(218,30,26)" fg:x="0" fg:w="218"/><text x="0.2500%" y="110.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (218 samples, 0.35%)</title><rect x="0.0000%" y="116" width="0.3463%" height="15" fill="rgb(220,122,19)" fg:x="0" fg:w="218"/><text x="0.2500%" y="126.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (218 samples, 0.35%)</title><rect x="0.0000%" y="132" width="0.3463%" height="15" fill="rgb(250,228,42)" fg:x="0" fg:w="218"/><text x="0.2500%" y="142.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (218 samples, 0.35%)</title><rect x="0.0000%" y="148" width="0.3463%" height="15" fill="rgb(240,193,28)" fg:x="0" fg:w="218"/><text x="0.2500%" y="158.50"></text></g><g><title>&lt;module&gt; (nnunet/run/default_configuration.py:20) (218 samples, 0.35%)</title><rect x="0.0000%" y="164" width="0.3463%" height="15" fill="rgb(216,20,37)" fg:x="0" fg:w="218"/><text x="0.2500%" y="174.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (218 samples, 0.35%)</title><rect x="0.0000%" y="180" width="0.3463%" height="15" fill="rgb(206,188,39)" fg:x="0" fg:w="218"/><text x="0.2500%" y="190.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (218 samples, 0.35%)</title><rect x="0.0000%" y="196" width="0.3463%" height="15" fill="rgb(217,207,13)" fg:x="0" fg:w="218"/><text x="0.2500%" y="206.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (218 samples, 0.35%)</title><rect x="0.0000%" y="212" width="0.3463%" height="15" fill="rgb(231,73,38)" fg:x="0" fg:w="218"/><text x="0.2500%" y="222.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (218 samples, 0.35%)</title><rect x="0.0000%" y="228" width="0.3463%" height="15" fill="rgb(225,20,46)" fg:x="0" fg:w="218"/><text x="0.2500%" y="238.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (218 samples, 0.35%)</title><rect x="0.0000%" y="244" width="0.3463%" height="15" fill="rgb(210,31,41)" fg:x="0" fg:w="218"/><text x="0.2500%" y="254.50"></text></g><g><title>&lt;module&gt; (nnunet/training/model_restore.py:20) (115 samples, 0.18%)</title><rect x="0.1636%" y="260" width="0.1827%" height="15" fill="rgb(221,200,47)" fg:x="103" fg:w="115"/><text x="0.4136%" y="270.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (115 samples, 0.18%)</title><rect x="0.1636%" y="276" width="0.1827%" height="15" fill="rgb(226,26,5)" fg:x="103" fg:w="115"/><text x="0.4136%" y="286.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (115 samples, 0.18%)</title><rect x="0.1636%" y="292" width="0.1827%" height="15" fill="rgb(249,33,26)" fg:x="103" fg:w="115"/><text x="0.4136%" y="302.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (115 samples, 0.18%)</title><rect x="0.1636%" y="308" width="0.1827%" height="15" fill="rgb(235,183,28)" fg:x="103" fg:w="115"/><text x="0.4136%" y="318.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (115 samples, 0.18%)</title><rect x="0.1636%" y="324" width="0.1827%" height="15" fill="rgb(221,5,38)" fg:x="103" fg:w="115"/><text x="0.4136%" y="334.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (115 samples, 0.18%)</title><rect x="0.1636%" y="340" width="0.1827%" height="15" fill="rgb(247,18,42)" fg:x="103" fg:w="115"/><text x="0.4136%" y="350.50"></text></g><g><title>initialize (nnunet/training/network_training/nnUNetTrainerV2.py:105) (80 samples, 0.13%)</title><rect x="0.3574%" y="100" width="0.1271%" height="15" fill="rgb(241,131,45)" fg:x="225" fg:w="80"/><text x="0.6074%" y="110.50"></text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (953 samples, 1.51%)</title><rect x="0.7720%" y="212" width="1.5138%" height="15" fill="rgb(249,31,29)" fg:x="486" fg:w="953"/><text x="1.0220%" y="222.50"></text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (942 samples, 1.50%)</title><rect x="0.7895%" y="228" width="1.4963%" height="15" fill="rgb(225,111,53)" fg:x="497" fg:w="942"/><text x="1.0395%" y="238.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (963 samples, 1.53%)</title><rect x="0.7704%" y="196" width="1.5297%" height="15" fill="rgb(238,160,17)" fg:x="485" fg:w="963"/><text x="1.0204%" y="206.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (1,006 samples, 1.60%)</title><rect x="0.7132%" y="180" width="1.5980%" height="15" fill="rgb(214,148,48)" fg:x="449" fg:w="1006"/><text x="0.9632%" y="190.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (1,065 samples, 1.69%)</title><rect x="0.6259%" y="164" width="1.6917%" height="15" fill="rgb(232,36,49)" fg:x="394" fg:w="1065"/><text x="0.8759%" y="174.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:132) (1,114 samples, 1.77%)</title><rect x="0.6179%" y="148" width="1.7695%" height="15" fill="rgb(209,103,24)" fg:x="389" fg:w="1114"/><text x="0.8679%" y="158.50"></text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (1,552 samples, 2.47%)</title><rect x="2.4462%" y="228" width="2.4653%" height="15" fill="rgb(229,88,8)" fg:x="1540" fg:w="1552"/><text x="2.6962%" y="238.50">re..</text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (1,546 samples, 2.46%)</title><rect x="2.4558%" y="244" width="2.4558%" height="15" fill="rgb(213,181,19)" fg:x="1546" fg:w="1546"/><text x="2.7058%" y="254.50">ka..</text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (1,562 samples, 2.48%)</title><rect x="2.4462%" y="212" width="2.4812%" height="15" fill="rgb(254,191,54)" fg:x="1540" fg:w="1562"/><text x="2.6962%" y="222.50">__..</text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (1,590 samples, 2.53%)</title><rect x="2.4081%" y="196" width="2.5257%" height="15" fill="rgb(241,83,37)" fg:x="1516" fg:w="1590"/><text x="2.6581%" y="206.50">__..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (1,596 samples, 2.54%)</title><rect x="2.4018%" y="180" width="2.5352%" height="15" fill="rgb(233,36,39)" fg:x="1512" fg:w="1596"/><text x="2.6518%" y="190.50">__..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:136) (1,638 samples, 2.60%)</title><rect x="2.3875%" y="148" width="2.6019%" height="15" fill="rgb(226,3,54)" fg:x="1503" fg:w="1638"/><text x="2.6375%" y="158.50">__..</text></g><g><title>&lt;listcomp&gt; (nnunet/network_architecture/generic_UNet.py:136) (1,638 samples, 2.60%)</title><rect x="2.3875%" y="164" width="2.6019%" height="15" fill="rgb(245,192,40)" fg:x="1503" fg:w="1638"/><text x="2.6375%" y="174.50">&lt;l..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:283) (2,777 samples, 4.41%)</title><rect x="0.5798%" y="132" width="4.4112%" height="15" fill="rgb(238,167,29)" fg:x="365" fg:w="2777"/><text x="0.8298%" y="142.50">__ini..</text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (804 samples, 1.28%)</title><rect x="5.0307%" y="212" width="1.2771%" height="15" fill="rgb(232,182,51)" fg:x="3167" fg:w="804"/><text x="5.2807%" y="222.50"></text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (803 samples, 1.28%)</title><rect x="5.0322%" y="228" width="1.2755%" height="15" fill="rgb(231,60,39)" fg:x="3168" fg:w="803"/><text x="5.2822%" y="238.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (812 samples, 1.29%)</title><rect x="5.0227%" y="164" width="1.2898%" height="15" fill="rgb(208,69,12)" fg:x="3162" fg:w="812"/><text x="5.2727%" y="174.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (812 samples, 1.29%)</title><rect x="5.0227%" y="180" width="1.2898%" height="15" fill="rgb(235,93,37)" fg:x="3162" fg:w="812"/><text x="5.2727%" y="190.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (807 samples, 1.28%)</title><rect x="5.0307%" y="196" width="1.2819%" height="15" fill="rgb(213,116,39)" fg:x="3167" fg:w="807"/><text x="5.2807%" y="206.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:313) (826 samples, 1.31%)</title><rect x="5.0132%" y="132" width="1.3121%" height="15" fill="rgb(222,207,29)" fg:x="3156" fg:w="826"/><text x="5.2632%" y="142.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:132) (821 samples, 1.30%)</title><rect x="5.0211%" y="148" width="1.3041%" height="15" fill="rgb(206,96,30)" fg:x="3161" fg:w="821"/><text x="5.2711%" y="158.50"></text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (715 samples, 1.14%)</title><rect x="6.3380%" y="212" width="1.1357%" height="15" fill="rgb(218,138,4)" fg:x="3990" fg:w="715"/><text x="6.5880%" y="222.50"></text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (714 samples, 1.13%)</title><rect x="6.3395%" y="228" width="1.1342%" height="15" fill="rgb(250,191,14)" fg:x="3991" fg:w="714"/><text x="6.5895%" y="238.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (717 samples, 1.14%)</title><rect x="6.3380%" y="196" width="1.1389%" height="15" fill="rgb(239,60,40)" fg:x="3990" fg:w="717"/><text x="6.5880%" y="206.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (721 samples, 1.15%)</title><rect x="6.3332%" y="180" width="1.1453%" height="15" fill="rgb(206,27,48)" fg:x="3987" fg:w="721"/><text x="6.5832%" y="190.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (723 samples, 1.15%)</title><rect x="6.3316%" y="164" width="1.1485%" height="15" fill="rgb(225,35,8)" fg:x="3986" fg:w="723"/><text x="6.5816%" y="174.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:316) (733 samples, 1.16%)</title><rect x="6.3253%" y="132" width="1.1643%" height="15" fill="rgb(250,213,24)" fg:x="3982" fg:w="733"/><text x="6.5753%" y="142.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:132) (731 samples, 1.16%)</title><rect x="6.3284%" y="148" width="1.1612%" height="15" fill="rgb(247,123,22)" fg:x="3984" fg:w="731"/><text x="6.5784%" y="158.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (396 samples, 0.63%)</title><rect x="7.5166%" y="180" width="0.6290%" height="15" fill="rgb(231,138,38)" fg:x="4732" fg:w="396"/><text x="7.7666%" y="190.50"></text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (395 samples, 0.63%)</title><rect x="7.5182%" y="196" width="0.6274%" height="15" fill="rgb(231,145,46)" fg:x="4733" fg:w="395"/><text x="7.7682%" y="206.50"></text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (392 samples, 0.62%)</title><rect x="7.5230%" y="212" width="0.6227%" height="15" fill="rgb(251,118,11)" fg:x="4736" fg:w="392"/><text x="7.7730%" y="222.50"></text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:343) (414 samples, 0.66%)</title><rect x="7.4928%" y="132" width="0.6576%" height="15" fill="rgb(217,147,25)" fg:x="4717" fg:w="414"/><text x="7.7428%" y="142.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:1092) (411 samples, 0.65%)</title><rect x="7.4975%" y="148" width="0.6529%" height="15" fill="rgb(247,81,37)" fg:x="4720" fg:w="411"/><text x="7.7475%" y="158.50"></text></g><g><title>__init__ (torch/nn/modules/conv.py:625) (411 samples, 0.65%)</title><rect x="7.4975%" y="164" width="0.6529%" height="15" fill="rgb(209,12,38)" fg:x="4720" fg:w="411"/><text x="7.7475%" y="174.50"></text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (2,822 samples, 4.48%)</title><rect x="8.1996%" y="212" width="4.4826%" height="15" fill="rgb(227,1,9)" fg:x="5162" fg:w="2822"/><text x="8.4496%" y="222.50">reset..</text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (2,819 samples, 4.48%)</title><rect x="8.2044%" y="228" width="4.4779%" height="15" fill="rgb(248,47,43)" fg:x="5165" fg:w="2819"/><text x="8.4544%" y="238.50">kaimi..</text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (2,827 samples, 4.49%)</title><rect x="8.1980%" y="196" width="4.4906%" height="15" fill="rgb(221,10,30)" fg:x="5161" fg:w="2827"/><text x="8.4480%" y="206.50">__ini..</text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (2,840 samples, 4.51%)</title><rect x="8.1790%" y="180" width="4.5112%" height="15" fill="rgb(210,229,1)" fg:x="5149" fg:w="2840"/><text x="8.4290%" y="190.50">__ini..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (2,845 samples, 4.52%)</title><rect x="8.1742%" y="164" width="4.5192%" height="15" fill="rgb(222,148,37)" fg:x="5146" fg:w="2845"/><text x="8.4242%" y="174.50">__ini..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:349) (2,872 samples, 4.56%)</title><rect x="8.1552%" y="132" width="4.5621%" height="15" fill="rgb(234,67,33)" fg:x="5134" fg:w="2872"/><text x="8.4052%" y="142.50">__ini..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:132) (2,863 samples, 4.55%)</title><rect x="8.1695%" y="148" width="4.5478%" height="15" fill="rgb(247,98,35)" fg:x="5143" fg:w="2863"/><text x="8.4195%" y="158.50">__ini..</text></g><g><title>reset_parameters (torch/nn/modules/conv.py:150) (1,229 samples, 1.95%)</title><rect x="12.7426%" y="212" width="1.9522%" height="15" fill="rgb(247,138,52)" fg:x="8022" fg:w="1229"/><text x="12.9926%" y="222.50">r..</text></g><g><title>kaiming_uniform_ (torch/nn/init.py:412) (1,228 samples, 1.95%)</title><rect x="12.7442%" y="228" width="1.9506%" height="15" fill="rgb(213,79,30)" fg:x="8023" fg:w="1228"/><text x="12.9942%" y="238.50">k..</text></g><g><title>__init__ (torch/nn/modules/conv.py:591) (1,240 samples, 1.97%)</title><rect x="12.7315%" y="180" width="1.9697%" height="15" fill="rgb(246,177,23)" fg:x="8015" fg:w="1240"/><text x="12.9815%" y="190.50">_..</text></g><g><title>__init__ (torch/nn/modules/conv.py:144) (1,233 samples, 1.96%)</title><rect x="12.7426%" y="196" width="1.9586%" height="15" fill="rgb(230,62,27)" fg:x="8022" fg:w="1233"/><text x="12.9926%" y="206.50">_..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:55) (1,243 samples, 1.97%)</title><rect x="12.7299%" y="164" width="1.9745%" height="15" fill="rgb(216,154,8)" fg:x="8014" fg:w="1243"/><text x="12.9799%" y="174.50">_..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:132) (1,258 samples, 2.00%)</title><rect x="12.7268%" y="148" width="1.9983%" height="15" fill="rgb(244,35,45)" fg:x="8012" fg:w="1258"/><text x="12.9768%" y="158.50">_..</text></g><g><title>__init__ (nnunet/network_architecture/generic_UNet.py:352) (1,266 samples, 2.01%)</title><rect x="12.7172%" y="132" width="2.0110%" height="15" fill="rgb(251,115,12)" fg:x="8006" fg:w="1266"/><text x="12.9672%" y="142.50">_..</text></g><g><title>initialize_network (nnunet/training/network_training/nnUNetTrainerV2.py:154) (8,943 samples, 14.21%)</title><rect x="0.5528%" y="116" width="14.2056%" height="15" fill="rgb(240,54,50)" fg:x="348" fg:w="8943"/><text x="0.8028%" y="126.50">initialize_network (nn..</text></g><g><title>&lt;lambda&gt; (torch/nn/modules/module.py:905) (111 samples, 0.18%)</title><rect x="14.7584%" y="260" width="0.1763%" height="15" fill="rgb(233,84,52)" fg:x="9291" fg:w="111"/><text x="15.0084%" y="270.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (112 samples, 0.18%)</title><rect x="14.7584%" y="228" width="0.1779%" height="15" fill="rgb(207,117,47)" fg:x="9291" fg:w="112"/><text x="15.0084%" y="238.50"></text></g><g><title>_apply (torch/nn/modules/module.py:820) (112 samples, 0.18%)</title><rect x="14.7584%" y="244" width="0.1779%" height="15" fill="rgb(249,43,39)" fg:x="9291" fg:w="112"/><text x="15.0084%" y="254.50"></text></g><g><title>initialize (nnunet/training/network_training/nnUNetTrainerV2.py:121) (9,058 samples, 14.39%)</title><rect x="0.5496%" y="100" width="14.3883%" height="15" fill="rgb(209,38,44)" fg:x="346" fg:w="9058"/><text x="0.7996%" y="110.50">initialize (nnunet/tra..</text></g><g><title>initialize_network (nnunet/training/network_training/nnUNetTrainerV2.py:161) (113 samples, 0.18%)</title><rect x="14.7584%" y="116" width="0.1795%" height="15" fill="rgb(236,212,23)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="126.50"></text></g><g><title>cuda (torch/nn/modules/module.py:905) (113 samples, 0.18%)</title><rect x="14.7584%" y="132" width="0.1795%" height="15" fill="rgb(242,79,21)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="142.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (113 samples, 0.18%)</title><rect x="14.7584%" y="148" width="0.1795%" height="15" fill="rgb(211,96,35)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="158.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (113 samples, 0.18%)</title><rect x="14.7584%" y="164" width="0.1795%" height="15" fill="rgb(253,215,40)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="174.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (113 samples, 0.18%)</title><rect x="14.7584%" y="180" width="0.1795%" height="15" fill="rgb(211,81,21)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="190.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (113 samples, 0.18%)</title><rect x="14.7584%" y="196" width="0.1795%" height="15" fill="rgb(208,190,38)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="206.50"></text></g><g><title>_apply (torch/nn/modules/module.py:797) (113 samples, 0.18%)</title><rect x="14.7584%" y="212" width="0.1795%" height="15" fill="rgb(235,213,38)" fg:x="9291" fg:w="113"/><text x="15.0084%" y="222.50"></text></g><g><title>isfile (genericpath.py:30) (495 samples, 0.79%)</title><rect x="15.3064%" y="164" width="0.7863%" height="15" fill="rgb(237,122,38)" fg:x="9636" fg:w="495"/><text x="15.5564%" y="174.50"></text></g><g><title>isfile (genericpath.py:33) (80 samples, 0.13%)</title><rect x="16.0927%" y="164" width="0.1271%" height="15" fill="rgb(244,218,35)" fg:x="10131" fg:w="80"/><text x="16.3427%" y="174.50"></text></g><g><title>join (posixpath.py:77) (100 samples, 0.16%)</title><rect x="16.2627%" y="164" width="0.1588%" height="15" fill="rgb(240,68,47)" fg:x="10238" fg:w="100"/><text x="16.5127%" y="174.50"></text></g><g><title>join (posixpath.py:82) (77 samples, 0.12%)</title><rect x="16.4406%" y="164" width="0.1223%" height="15" fill="rgb(210,16,53)" fg:x="10350" fg:w="77"/><text x="16.6906%" y="174.50"></text></g><g><title>join (posixpath.py:85) (84 samples, 0.13%)</title><rect x="16.6201%" y="164" width="0.1334%" height="15" fill="rgb(235,124,12)" fg:x="10463" fg:w="84"/><text x="16.8701%" y="174.50"></text></g><g><title>&lt;listcomp&gt; (batchgenerators/utilities/file_and_folder_operations.py:40) (1,092 samples, 1.73%)</title><rect x="15.0650%" y="148" width="1.7346%" height="15" fill="rgb(224,169,11)" fg:x="9484" fg:w="1092"/><text x="15.3150%" y="158.50"></text></g><g><title>subfiles (batchgenerators/utilities/file_and_folder_operations.py:40) (1,139 samples, 1.81%)</title><rect x="15.0650%" y="132" width="1.8093%" height="15" fill="rgb(250,166,2)" fg:x="9484" fg:w="1139"/><text x="15.3150%" y="142.50">s..</text></g><g><title>unpack_dataset (nnunet/training/dataloading/dataset_loading.py:67) (1,475 samples, 2.34%)</title><rect x="15.0650%" y="116" width="2.3430%" height="15" fill="rgb(242,216,29)" fg:x="9484" fg:w="1475"/><text x="15.3150%" y="126.50">u..</text></g><g><title>subfiles (batchgenerators/utilities/file_and_folder_operations.py:44) (336 samples, 0.53%)</title><rect x="16.8742%" y="132" width="0.5337%" height="15" fill="rgb(230,116,27)" fg:x="10623" fg:w="336"/><text x="17.1242%" y="142.50"></text></g><g><title>_map_async (multiprocessing/pool.py:475) (747 samples, 1.19%)</title><rect x="17.4492%" y="148" width="1.1866%" height="15" fill="rgb(228,99,48)" fg:x="10985" fg:w="747"/><text x="17.6992%" y="158.50"></text></g><g><title>_map_async (multiprocessing/pool.py:485) (85 samples, 0.14%)</title><rect x="18.6358%" y="148" width="0.1350%" height="15" fill="rgb(253,11,6)" fg:x="11732" fg:w="85"/><text x="18.8858%" y="158.50"></text></g><g><title>unpack_dataset (nnunet/training/dataloading/dataset_loading.py:68) (863 samples, 1.37%)</title><rect x="17.4079%" y="116" width="1.3708%" height="15" fill="rgb(247,143,39)" fg:x="10959" fg:w="863"/><text x="17.6579%" y="126.50"></text></g><g><title>map (multiprocessing/pool.py:364) (843 samples, 1.34%)</title><rect x="17.4397%" y="132" width="1.3391%" height="15" fill="rgb(236,97,10)" fg:x="10979" fg:w="843"/><text x="17.6897%" y="142.50"></text></g><g><title>unpack_dataset (nnunet/training/dataloading/dataset_loading.py:69) (81 samples, 0.13%)</title><rect x="18.7788%" y="116" width="0.1287%" height="15" fill="rgb(233,208,19)" fg:x="11822" fg:w="81"/><text x="19.0288%" y="126.50"></text></g><g><title>join (multiprocessing/pool.py:662) (159 samples, 0.25%)</title><rect x="18.9376%" y="132" width="0.2526%" height="15" fill="rgb(216,164,2)" fg:x="11922" fg:w="159"/><text x="19.1876%" y="142.50"></text></g><g><title>initialize (nnunet/training/network_training/nnUNetTrainerV2.py:98) (2,690 samples, 4.27%)</title><rect x="14.9427%" y="100" width="4.2730%" height="15" fill="rgb(220,129,5)" fg:x="9407" fg:w="2690"/><text x="15.1927%" y="110.50">initi..</text></g><g><title>unpack_dataset (nnunet/training/dataloading/dataset_loading.py:70) (194 samples, 0.31%)</title><rect x="18.9075%" y="116" width="0.3082%" height="15" fill="rgb(242,17,10)" fg:x="11903" fg:w="194"/><text x="19.1575%" y="126.50"></text></g><g><title>main (nnunet/run/run_training.py:167) (11,876 samples, 18.86%)</title><rect x="0.3574%" y="84" width="18.8646%" height="15" fill="rgb(242,107,0)" fg:x="225" fg:w="11876"/><text x="0.6074%" y="94.50">main (nnunet/run/run_training..</text></g><g><title>run_iteration (nnunet/training/network_training/nnUNetTrainerV2.py:241) (216 samples, 0.34%)</title><rect x="19.5587%" y="148" width="0.3431%" height="15" fill="rgb(251,28,31)" fg:x="12313" fg:w="216"/><text x="19.8087%" y="158.50"></text></g><g><title>to_cuda (nnunet/utilities/to_torch.py:28) (216 samples, 0.34%)</title><rect x="19.5587%" y="164" width="0.3431%" height="15" fill="rgb(233,223,10)" fg:x="12313" fg:w="216"/><text x="19.8087%" y="174.50"></text></g><g><title>&lt;listcomp&gt; (nnunet/utilities/to_torch.py:28) (216 samples, 0.34%)</title><rect x="19.5587%" y="180" width="0.3431%" height="15" fill="rgb(215,21,27)" fg:x="12313" fg:w="216"/><text x="19.8087%" y="190.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:65) (7,754 samples, 12.32%)</title><rect x="19.9844%" y="276" width="12.3169%" height="15" fill="rgb(232,23,21)" fg:x="12581" fg:w="7754"/><text x="20.2344%" y="286.50">forward (nnunet/ne..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (7,746 samples, 12.30%)</title><rect x="19.9971%" y="292" width="12.3042%" height="15" fill="rgb(244,5,23)" fg:x="12589" fg:w="7746"/><text x="20.2471%" y="302.50">_call_impl (torch/..</text></g><g><title>forward (torch/nn/modules/conv.py:613) (7,746 samples, 12.30%)</title><rect x="19.9971%" y="308" width="12.3042%" height="15" fill="rgb(226,81,46)" fg:x="12589" fg:w="7746"/><text x="20.2471%" y="318.50">forward (torch/nn/..</text></g><g><title>_conv_forward (torch/nn/modules/conv.py:608) (7,744 samples, 12.30%)</title><rect x="20.0003%" y="324" width="12.3010%" height="15" fill="rgb(247,70,30)" fg:x="12591" fg:w="7744"/><text x="20.2503%" y="334.50">_conv_forward (tor..</text></g><g><title>instance_norm (torch/nn/functional.py:2495) (386 samples, 0.61%)</title><rect x="32.4173%" y="340" width="0.6131%" height="15" fill="rgb(212,68,19)" fg:x="20408" fg:w="386"/><text x="32.6673%" y="350.50"></text></g><g><title>_apply_instance_norm (torch/nn/modules/instancenorm.py:34) (396 samples, 0.63%)</title><rect x="32.4110%" y="324" width="0.6290%" height="15" fill="rgb(240,187,13)" fg:x="20404" fg:w="396"/><text x="32.6610%" y="334.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:391) (8,232 samples, 13.08%)</title><rect x="19.9654%" y="180" width="13.0762%" height="15" fill="rgb(223,113,26)" fg:x="12569" fg:w="8232"/><text x="20.2154%" y="190.50">forward (nnunet/netw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (8,227 samples, 13.07%)</title><rect x="19.9733%" y="196" width="13.0683%" height="15" fill="rgb(206,192,2)" fg:x="12574" fg:w="8227"/><text x="20.2233%" y="206.50">_call_impl (torch/nn..</text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:142) (8,227 samples, 13.07%)</title><rect x="19.9733%" y="212" width="13.0683%" height="15" fill="rgb(241,108,4)" fg:x="12574" fg:w="8227"/><text x="20.2233%" y="222.50">forward (nnunet/netw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (8,224 samples, 13.06%)</title><rect x="19.9781%" y="228" width="13.0635%" height="15" fill="rgb(247,173,49)" fg:x="12577" fg:w="8224"/><text x="20.2281%" y="238.50">_call_impl (torch/nn..</text></g><g><title>forward (torch/nn/modules/container.py:217) (8,222 samples, 13.06%)</title><rect x="19.9813%" y="244" width="13.0603%" height="15" fill="rgb(224,114,35)" fg:x="12579" fg:w="8222"/><text x="20.2313%" y="254.50">forward (torch/nn/mo..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (8,220 samples, 13.06%)</title><rect x="19.9844%" y="260" width="13.0572%" height="15" fill="rgb(245,159,27)" fg:x="12581" fg:w="8220"/><text x="20.2344%" y="270.50">_call_impl (torch/nn..</text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:68) (464 samples, 0.74%)</title><rect x="32.3045%" y="276" width="0.7370%" height="15" fill="rgb(245,172,44)" fg:x="20337" fg:w="464"/><text x="32.5545%" y="286.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (447 samples, 0.71%)</title><rect x="32.3315%" y="292" width="0.7100%" height="15" fill="rgb(236,23,11)" fg:x="20354" fg:w="447"/><text x="32.5815%" y="302.50"></text></g><g><title>forward (torch/nn/modules/instancenorm.py:74) (397 samples, 0.63%)</title><rect x="32.4110%" y="308" width="0.6306%" height="15" fill="rgb(205,117,38)" fg:x="20404" fg:w="397"/><text x="32.6610%" y="318.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:65) (131 samples, 0.21%)</title><rect x="33.0464%" y="308" width="0.2081%" height="15" fill="rgb(237,72,25)" fg:x="20804" fg:w="131"/><text x="33.2964%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (127 samples, 0.20%)</title><rect x="33.0527%" y="324" width="0.2017%" height="15" fill="rgb(244,70,9)" fg:x="20808" fg:w="127"/><text x="33.3027%" y="334.50"></text></g><g><title>forward (torch/nn/modules/conv.py:613) (127 samples, 0.20%)</title><rect x="33.0527%" y="340" width="0.2017%" height="15" fill="rgb(217,125,39)" fg:x="20808" fg:w="127"/><text x="33.3027%" y="350.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:608) (126 samples, 0.20%)</title><rect x="33.0543%" y="356" width="0.2001%" height="15" fill="rgb(235,36,10)" fg:x="20809" fg:w="126"/><text x="33.3043%" y="366.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:396) (173 samples, 0.27%)</title><rect x="33.0416%" y="180" width="0.2748%" height="15" fill="rgb(251,123,47)" fg:x="20801" fg:w="173"/><text x="33.2916%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (172 samples, 0.27%)</title><rect x="33.0432%" y="196" width="0.2732%" height="15" fill="rgb(221,13,13)" fg:x="20802" fg:w="172"/><text x="33.2932%" y="206.50"></text></g><g><title>forward (torch/nn/modules/container.py:217) (172 samples, 0.27%)</title><rect x="33.0432%" y="212" width="0.2732%" height="15" fill="rgb(238,131,9)" fg:x="20802" fg:w="172"/><text x="33.2932%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (171 samples, 0.27%)</title><rect x="33.0448%" y="228" width="0.2716%" height="15" fill="rgb(211,50,8)" fg:x="20803" fg:w="171"/><text x="33.2948%" y="238.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:142) (170 samples, 0.27%)</title><rect x="33.0464%" y="244" width="0.2700%" height="15" fill="rgb(245,182,24)" fg:x="20804" fg:w="170"/><text x="33.2964%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (170 samples, 0.27%)</title><rect x="33.0464%" y="260" width="0.2700%" height="15" fill="rgb(242,14,37)" fg:x="20804" fg:w="170"/><text x="33.2964%" y="270.50"></text></g><g><title>forward (torch/nn/modules/container.py:217) (170 samples, 0.27%)</title><rect x="33.0464%" y="276" width="0.2700%" height="15" fill="rgb(246,228,12)" fg:x="20804" fg:w="170"/><text x="33.2964%" y="286.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (170 samples, 0.27%)</title><rect x="33.0464%" y="292" width="0.2700%" height="15" fill="rgb(213,55,15)" fg:x="20804" fg:w="170"/><text x="33.2964%" y="302.50"></text></g><g><title>forward (torch/nn/modules/conv.py:1108) (195 samples, 0.31%)</title><rect x="33.3275%" y="212" width="0.3097%" height="15" fill="rgb(209,9,3)" fg:x="20981" fg:w="195"/><text x="33.5775%" y="222.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:399) (201 samples, 0.32%)</title><rect x="33.3196%" y="180" width="0.3193%" height="15" fill="rgb(230,59,30)" fg:x="20976" fg:w="201"/><text x="33.5696%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (197 samples, 0.31%)</title><rect x="33.3259%" y="196" width="0.3129%" height="15" fill="rgb(209,121,21)" fg:x="20980" fg:w="197"/><text x="33.5759%" y="206.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:65) (451 samples, 0.72%)</title><rect x="33.7199%" y="308" width="0.7164%" height="15" fill="rgb(220,109,13)" fg:x="21228" fg:w="451"/><text x="33.9699%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (447 samples, 0.71%)</title><rect x="33.7262%" y="324" width="0.7100%" height="15" fill="rgb(232,18,1)" fg:x="21232" fg:w="447"/><text x="33.9762%" y="334.50"></text></g><g><title>forward (torch/nn/modules/conv.py:613) (446 samples, 0.71%)</title><rect x="33.7278%" y="340" width="0.7085%" height="15" fill="rgb(215,41,42)" fg:x="21233" fg:w="446"/><text x="33.9778%" y="350.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:608) (444 samples, 0.71%)</title><rect x="33.7310%" y="356" width="0.7053%" height="15" fill="rgb(224,123,36)" fg:x="21235" fg:w="444"/><text x="33.9810%" y="366.50"></text></g><g><title>instance_norm (torch/nn/functional.py:2495) (109 samples, 0.17%)</title><rect x="34.5602%" y="372" width="0.1731%" height="15" fill="rgb(240,125,3)" fg:x="21757" fg:w="109"/><text x="34.8102%" y="382.50"></text></g><g><title>_apply_instance_norm (torch/nn/modules/instancenorm.py:34) (123 samples, 0.20%)</title><rect x="34.5474%" y="356" width="0.1954%" height="15" fill="rgb(205,98,50)" fg:x="21749" fg:w="123"/><text x="34.7974%" y="366.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:401) (674 samples, 1.07%)</title><rect x="33.6786%" y="180" width="1.0706%" height="15" fill="rgb(205,185,37)" fg:x="21202" fg:w="674"/><text x="33.9286%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (664 samples, 1.05%)</title><rect x="33.6944%" y="196" width="1.0547%" height="15" fill="rgb(238,207,15)" fg:x="21212" fg:w="664"/><text x="33.9444%" y="206.50"></text></g><g><title>forward (torch/nn/modules/container.py:217) (662 samples, 1.05%)</title><rect x="33.6976%" y="212" width="1.0516%" height="15" fill="rgb(213,199,42)" fg:x="21214" fg:w="662"/><text x="33.9476%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (659 samples, 1.05%)</title><rect x="33.7024%" y="228" width="1.0468%" height="15" fill="rgb(235,201,11)" fg:x="21217" fg:w="659"/><text x="33.9524%" y="238.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:142) (657 samples, 1.04%)</title><rect x="33.7056%" y="244" width="1.0436%" height="15" fill="rgb(207,46,11)" fg:x="21219" fg:w="657"/><text x="33.9556%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (651 samples, 1.03%)</title><rect x="33.7151%" y="260" width="1.0341%" height="15" fill="rgb(241,35,35)" fg:x="21225" fg:w="651"/><text x="33.9651%" y="270.50"></text></g><g><title>forward (torch/nn/modules/container.py:217) (649 samples, 1.03%)</title><rect x="33.7183%" y="276" width="1.0309%" height="15" fill="rgb(243,32,47)" fg:x="21227" fg:w="649"/><text x="33.9683%" y="286.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (649 samples, 1.03%)</title><rect x="33.7183%" y="292" width="1.0309%" height="15" fill="rgb(247,202,23)" fg:x="21227" fg:w="649"/><text x="33.9683%" y="302.50"></text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:68) (197 samples, 0.31%)</title><rect x="34.4363%" y="308" width="0.3129%" height="15" fill="rgb(219,102,11)" fg:x="21679" fg:w="197"/><text x="34.6863%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (180 samples, 0.29%)</title><rect x="34.4633%" y="324" width="0.2859%" height="15" fill="rgb(243,110,44)" fg:x="21696" fg:w="180"/><text x="34.7133%" y="334.50"></text></g><g><title>forward (torch/nn/modules/instancenorm.py:74) (129 samples, 0.20%)</title><rect x="34.5443%" y="340" width="0.2049%" height="15" fill="rgb(222,74,54)" fg:x="21747" fg:w="129"/><text x="34.7943%" y="350.50"></text></g><g><title>run_iteration (nnunet/training/network_training/nnUNetTrainerV2.py:247) (9,535 samples, 15.15%)</title><rect x="19.9638%" y="148" width="15.1460%" height="15" fill="rgb(216,99,12)" fg:x="12568" fg:w="9535"/><text x="20.2138%" y="158.50">run_iteration (nnunet/t..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (9,534 samples, 15.14%)</title><rect x="19.9654%" y="164" width="15.1444%" height="15" fill="rgb(226,22,26)" fg:x="12569" fg:w="9534"/><text x="20.2154%" y="174.50">_call_impl (torch/nn/mo..</text></g><g><title>forward (nnunet/network_architecture/generic_UNet.py:402) (227 samples, 0.36%)</title><rect x="34.7492%" y="180" width="0.3606%" height="15" fill="rgb(217,163,10)" fg:x="21876" fg:w="227"/><text x="34.9992%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (218 samples, 0.35%)</title><rect x="34.7635%" y="196" width="0.3463%" height="15" fill="rgb(213,25,53)" fg:x="21885" fg:w="218"/><text x="35.0135%" y="206.50"></text></g><g><title>forward (torch/nn/modules/conv.py:613) (218 samples, 0.35%)</title><rect x="34.7635%" y="212" width="0.3463%" height="15" fill="rgb(252,105,26)" fg:x="21885" fg:w="218"/><text x="35.0135%" y="222.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:608) (217 samples, 0.34%)</title><rect x="34.7651%" y="228" width="0.3447%" height="15" fill="rgb(220,39,43)" fg:x="21886" fg:w="217"/><text x="35.0151%" y="238.50"></text></g><g><title>forward (nnunet/training/loss_functions/dice_loss.py:178) (87 samples, 0.14%)</title><rect x="35.1447%" y="244" width="0.1382%" height="15" fill="rgb(229,68,48)" fg:x="22125" fg:w="87"/><text x="35.3947%" y="254.50"></text></g><g><title>forward (nnunet/training/loss_functions/dice_loss.py:347) (141 samples, 0.22%)</title><rect x="35.1336%" y="212" width="0.2240%" height="15" fill="rgb(252,8,32)" fg:x="22118" fg:w="141"/><text x="35.3836%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (141 samples, 0.22%)</title><rect x="35.1336%" y="228" width="0.2240%" height="15" fill="rgb(223,20,43)" fg:x="22118" fg:w="141"/><text x="35.3836%" y="238.50"></text></g><g><title>forward (nnunet/training/loss_functions/deep_supervision.py:39) (205 samples, 0.33%)</title><rect x="35.1177%" y="180" width="0.3256%" height="15" fill="rgb(229,81,49)" fg:x="22108" fg:w="205"/><text x="35.3677%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (197 samples, 0.31%)</title><rect x="35.1304%" y="196" width="0.3129%" height="15" fill="rgb(236,28,36)" fg:x="22116" fg:w="197"/><text x="35.3804%" y="206.50"></text></g><g><title>forward (nnunet/training/loss_functions/dice_loss.py:178) (241 samples, 0.38%)</title><rect x="35.5021%" y="244" width="0.3828%" height="15" fill="rgb(249,185,26)" fg:x="22350" fg:w="241"/><text x="35.7521%" y="254.50"></text></g><g><title>forward (nnunet/training/loss_functions/dice_loss.py:347) (360 samples, 0.57%)</title><rect x="35.4783%" y="212" width="0.5718%" height="15" fill="rgb(249,174,33)" fg:x="22335" fg:w="360"/><text x="35.7283%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (359 samples, 0.57%)</title><rect x="35.4799%" y="228" width="0.5703%" height="15" fill="rgb(233,201,37)" fg:x="22336" fg:w="359"/><text x="35.7299%" y="238.50"></text></g><g><title>forward (nnunet/training/loss_functions/crossentropy.py:20) (90 samples, 0.14%)</title><rect x="36.1057%" y="244" width="0.1430%" height="15" fill="rgb(221,78,26)" fg:x="22730" fg:w="90"/><text x="36.3557%" y="254.50"></text></g><g><title>forward (nnunet/training/loss_functions/dice_loss.py:351) (132 samples, 0.21%)</title><rect x="36.0501%" y="212" width="0.2097%" height="15" fill="rgb(250,127,30)" fg:x="22695" fg:w="132"/><text x="36.3001%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (114 samples, 0.18%)</title><rect x="36.0787%" y="228" width="0.1811%" height="15" fill="rgb(230,49,44)" fg:x="22713" fg:w="114"/><text x="36.3287%" y="238.50"></text></g><g><title>run_iteration (nnunet/training/network_training/nnUNetTrainerV2.py:249) (742 samples, 1.18%)</title><rect x="35.1098%" y="148" width="1.1786%" height="15" fill="rgb(229,67,23)" fg:x="22103" fg:w="742"/><text x="35.3598%" y="158.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (738 samples, 1.17%)</title><rect x="35.1161%" y="164" width="1.1723%" height="15" fill="rgb(249,83,47)" fg:x="22107" fg:w="738"/><text x="35.3661%" y="174.50"></text></g><g><title>forward (nnunet/training/loss_functions/deep_supervision.py:42) (530 samples, 0.84%)</title><rect x="35.4465%" y="180" width="0.8419%" height="15" fill="rgb(215,43,3)" fg:x="22315" fg:w="530"/><text x="35.6965%" y="190.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1501) (511 samples, 0.81%)</title><rect x="35.4767%" y="196" width="0.8117%" height="15" fill="rgb(238,154,13)" fg:x="22334" fg:w="511"/><text x="35.7267%" y="206.50"></text></g><g><title>run_iteration (nnunet/training/network_training/nnUNetTrainerV2.py:254) (130 samples, 0.21%)</title><rect x="36.3917%" y="148" width="0.2065%" height="15" fill="rgb(219,56,2)" fg:x="22910" fg:w="130"/><text x="36.6417%" y="158.50"></text></g><g><title>step (torch/optim/sgd.py:76) (82 samples, 0.13%)</title><rect x="36.6267%" y="228" width="0.1303%" height="15" fill="rgb(233,0,4)" fg:x="23058" fg:w="82"/><text x="36.8767%" y="238.50"></text></g><g><title>sgd (torch/optim/sgd.py:222) (79 samples, 0.13%)</title><rect x="36.6315%" y="244" width="0.1255%" height="15" fill="rgb(235,30,7)" fg:x="23061" fg:w="79"/><text x="36.8815%" y="254.50"></text></g><g><title>wrapper (torch/optim/optimizer.py:280) (95 samples, 0.15%)</title><rect x="36.6077%" y="196" width="0.1509%" height="15" fill="rgb(250,79,13)" fg:x="23046" fg:w="95"/><text x="36.8577%" y="206.50"></text></g><g><title>_use_grad (torch/optim/optimizer.py:33) (95 samples, 0.15%)</title><rect x="36.6077%" y="212" width="0.1509%" height="15" fill="rgb(211,146,34)" fg:x="23046" fg:w="95"/><text x="36.8577%" y="222.50"></text></g><g><title>run_iteration (nnunet/training/network_training/nnUNetTrainerV2.py:255) (105 samples, 0.17%)</title><rect x="36.5982%" y="148" width="0.1668%" height="15" fill="rgb(228,22,38)" fg:x="23040" fg:w="105"/><text x="36.8482%" y="158.50"></text></g><g><title>step (torch/cuda/amp/grad_scaler.py:374) (105 samples, 0.17%)</title><rect x="36.5982%" y="164" width="0.1668%" height="15" fill="rgb(235,168,5)" fg:x="23040" fg:w="105"/><text x="36.8482%" y="174.50"></text></g><g><title>_maybe_opt_step (torch/cuda/amp/grad_scaler.py:290) (104 samples, 0.17%)</title><rect x="36.5997%" y="180" width="0.1652%" height="15" fill="rgb(221,155,16)" fg:x="23041" fg:w="104"/><text x="36.8497%" y="190.50"></text></g><g><title>&lt;module&gt; (nnunet/run/run_training.py:206) (22,934 samples, 36.43%)</title><rect x="0.3463%" y="68" width="36.4298%" height="15" fill="rgb(215,215,53)" fg:x="218" fg:w="22934"/><text x="0.5963%" y="78.50">&lt;module&gt; (nnunet/run/run_training.py:206)</text></g><g><title>main (nnunet/run/run_training.py:183) (11,051 samples, 17.55%)</title><rect x="19.2220%" y="84" width="17.5541%" height="15" fill="rgb(223,4,10)" fg:x="12101" fg:w="11051"/><text x="19.4720%" y="94.50">main (nnunet/run/run_traini..</text></g><g><title>run_training (nnunet/training/network_training/nnUNetTrainerV2.py:440) (11,051 samples, 17.55%)</title><rect x="19.2220%" y="100" width="17.5541%" height="15" fill="rgb(234,103,6)" fg:x="12101" fg:w="11051"/><text x="19.4720%" y="110.50">run_training (nnunet/traini..</text></g><g><title>run_training (nnunet/training/network_training/nnUNetTrainer.py:318) (11,024 samples, 17.51%)</title><rect x="19.2649%" y="116" width="17.5112%" height="15" fill="rgb(227,97,0)" fg:x="12128" fg:w="11024"/><text x="19.5149%" y="126.50">run_training (nnunet/traini..</text></g><g><title>run_training (nnunet/training/network_training/network_trainer.py:456) (10,912 samples, 17.33%)</title><rect x="19.4428%" y="132" width="17.3333%" height="15" fill="rgb(234,150,53)" fg:x="12240" fg:w="10912"/><text x="19.6928%" y="142.50">run_training (nnunet/traini..</text></g><g><title>_recv (multiprocessing/connection.py:379) (3,004 samples, 4.77%)</title><rect x="36.8269%" y="164" width="4.7717%" height="15" fill="rgb(228,201,54)" fg:x="23184" fg:w="3004"/><text x="37.0769%" y="174.50">_recv ..</text></g><g><title>_recv_bytes (multiprocessing/connection.py:414) (3,018 samples, 4.79%)</title><rect x="36.8142%" y="148" width="4.7940%" height="15" fill="rgb(222,22,37)" fg:x="23176" fg:w="3018"/><text x="37.0642%" y="158.50">_recv_..</text></g><g><title>_recv (multiprocessing/connection.py:379) (108 samples, 0.17%)</title><rect x="41.6749%" y="164" width="0.1716%" height="15" fill="rgb(237,53,32)" fg:x="26236" fg:w="108"/><text x="41.9249%" y="174.50"></text></g><g><title>recv (multiprocessing/connection.py:250) (3,177 samples, 5.05%)</title><rect x="36.8110%" y="132" width="5.0465%" height="15" fill="rgb(233,25,53)" fg:x="23174" fg:w="3177"/><text x="37.0610%" y="142.50">recv (..</text></g><g><title>_recv_bytes (multiprocessing/connection.py:421) (126 samples, 0.20%)</title><rect x="41.6574%" y="148" width="0.2001%" height="15" fill="rgb(210,40,34)" fg:x="26225" fg:w="126"/><text x="41.9074%" y="158.50"></text></g><g><title>_handle_results (multiprocessing/pool.py:576) (3,283 samples, 5.21%)</title><rect x="36.7840%" y="116" width="5.2149%" height="15" fill="rgb(241,220,44)" fg:x="23157" fg:w="3283"/><text x="37.0340%" y="126.50">_handl..</text></g><g><title>recv (multiprocessing/connection.py:251) (89 samples, 0.14%)</title><rect x="41.8575%" y="132" width="0.1414%" height="15" fill="rgb(235,28,35)" fg:x="26351" fg:w="89"/><text x="42.1075%" y="142.50"></text></g><g><title>_handle_tasks (multiprocessing/pool.py:528) (2,511 samples, 3.99%)</title><rect x="42.1371%" y="116" width="3.9886%" height="15" fill="rgb(210,56,17)" fg:x="26527" fg:w="2511"/><text x="42.3871%" y="126.50">_han..</text></g><g><title>_guarded_task_generation (multiprocessing/pool.py:388) (98 samples, 0.16%)</title><rect x="46.1369%" y="132" width="0.1557%" height="15" fill="rgb(224,130,29)" fg:x="29045" fg:w="98"/><text x="46.3869%" y="142.50"></text></g><g><title>_handle_tasks (multiprocessing/pool.py:532) (108 samples, 0.17%)</title><rect x="46.1257%" y="116" width="0.1716%" height="15" fill="rgb(235,212,8)" fg:x="29038" fg:w="108"/><text x="46.3757%" y="126.50"></text></g><g><title>_send (multiprocessing/connection.py:368) (92 samples, 0.15%)</title><rect x="46.4879%" y="164" width="0.1461%" height="15" fill="rgb(223,33,50)" fg:x="29266" fg:w="92"/><text x="46.7379%" y="174.50"></text></g><g><title>_send_bytes (multiprocessing/connection.py:411) (118 samples, 0.19%)</title><rect x="46.4482%" y="148" width="0.1874%" height="15" fill="rgb(219,149,13)" fg:x="29241" fg:w="118"/><text x="46.6982%" y="158.50"></text></g><g><title>dumps (multiprocessing/reduction.py:51) (475 samples, 0.75%)</title><rect x="46.6436%" y="148" width="0.7545%" height="15" fill="rgb(250,156,29)" fg:x="29364" fg:w="475"/><text x="46.8936%" y="158.50"></text></g><g><title>__init__ (multiprocessing/reduction.py:41) (74 samples, 0.12%)</title><rect x="47.2806%" y="164" width="0.1175%" height="15" fill="rgb(216,193,19)" fg:x="29765" fg:w="74"/><text x="47.5306%" y="174.50"></text></g><g><title>_handle_tasks (multiprocessing/pool.py:537) (696 samples, 1.11%)</title><rect x="46.3084%" y="116" width="1.1056%" height="15" fill="rgb(216,135,14)" fg:x="29153" fg:w="696"/><text x="46.5584%" y="126.50"></text></g><g><title>send (multiprocessing/connection.py:206) (672 samples, 1.07%)</title><rect x="46.3465%" y="132" width="1.0674%" height="15" fill="rgb(241,47,5)" fg:x="29177" fg:w="672"/><text x="46.5965%" y="142.50"></text></g><g><title>_handle_tasks (multiprocessing/pool.py:564) (79 samples, 0.13%)</title><rect x="47.5014%" y="116" width="0.1255%" height="15" fill="rgb(233,42,35)" fg:x="29904" fg:w="79"/><text x="47.7514%" y="126.50"></text></g><g><title>send (multiprocessing/connection.py:206) (75 samples, 0.12%)</title><rect x="47.5077%" y="132" width="0.1191%" height="15" fill="rgb(231,13,6)" fg:x="29908" fg:w="75"/><text x="47.7577%" y="142.50"></text></g><g><title>_handle_workers (multiprocessing/pool.py:513) (79 samples, 0.13%)</title><rect x="47.6538%" y="116" width="0.1255%" height="15" fill="rgb(207,181,40)" fg:x="30000" fg:w="79"/><text x="47.9038%" y="126.50"></text></g><g><title>_maintain_pool (multiprocessing/pool.py:336) (77 samples, 0.12%)</title><rect x="47.6570%" y="132" width="0.1223%" height="15" fill="rgb(254,173,49)" fg:x="30002" fg:w="77"/><text x="47.9070%" y="142.50"></text></g><g><title>_handle_workers (multiprocessing/pool.py:517) (112 samples, 0.18%)</title><rect x="47.7793%" y="116" width="0.1779%" height="15" fill="rgb(221,1,38)" fg:x="30079" fg:w="112"/><text x="48.0293%" y="126.50"></text></g><g><title>_get_worker_sentinels (multiprocessing/pool.py:283) (111 samples, 0.18%)</title><rect x="47.7809%" y="132" width="0.1763%" height="15" fill="rgb(206,124,46)" fg:x="30080" fg:w="111"/><text x="48.0309%" y="142.50"></text></g><g><title>&lt;listcomp&gt; (multiprocessing/pool.py:284) (75 samples, 0.12%)</title><rect x="47.8381%" y="148" width="0.1191%" height="15" fill="rgb(249,21,11)" fg:x="30116" fg:w="75"/><text x="48.0881%" y="158.50"></text></g><g><title>&lt;lambda&gt; (&lt;string&gt;:1) (126 samples, 0.20%)</title><rect x="48.2527%" y="196" width="0.2001%" height="15" fill="rgb(222,201,40)" fg:x="30377" fg:w="126"/><text x="48.5027%" y="206.50"></text></g><g><title>register (selectors.py:239) (159 samples, 0.25%)</title><rect x="48.2193%" y="180" width="0.2526%" height="15" fill="rgb(235,61,29)" fg:x="30356" fg:w="159"/><text x="48.4693%" y="190.50"></text></g><g><title>register (selectors.py:353) (229 samples, 0.36%)</title><rect x="48.1113%" y="164" width="0.3638%" height="15" fill="rgb(219,207,3)" fg:x="30288" fg:w="229"/><text x="48.3613%" y="174.50"></text></g><g><title>wait (multiprocessing/connection.py:925) (279 samples, 0.44%)</title><rect x="48.0875%" y="148" width="0.4432%" height="15" fill="rgb(222,56,46)" fg:x="30273" fg:w="279"/><text x="48.3375%" y="158.50"></text></g><g><title>_wait_for_updates (multiprocessing/pool.py:499) (378 samples, 0.60%)</title><rect x="47.9731%" y="132" width="0.6004%" height="15" fill="rgb(239,76,54)" fg:x="30201" fg:w="378"/><text x="48.2231%" y="142.50"></text></g><g><title>wait (multiprocessing/connection.py:923) (76 samples, 0.12%)</title><rect x="48.6022%" y="196" width="0.1207%" height="15" fill="rgb(231,124,27)" fg:x="30597" fg:w="76"/><text x="48.8522%" y="206.50"></text></g><g><title>_poll (multiprocessing/connection.py:424) (128 samples, 0.20%)</title><rect x="48.5958%" y="180" width="0.2033%" height="15" fill="rgb(249,195,6)" fg:x="30593" fg:w="128"/><text x="48.8458%" y="190.50"></text></g><g><title>_wait_for_updates (multiprocessing/pool.py:500) (143 samples, 0.23%)</title><rect x="48.5736%" y="132" width="0.2271%" height="15" fill="rgb(237,174,47)" fg:x="30579" fg:w="143"/><text x="48.8236%" y="142.50"></text></g><g><title>empty (multiprocessing/queues.py:353) (141 samples, 0.22%)</title><rect x="48.5767%" y="148" width="0.2240%" height="15" fill="rgb(206,201,31)" fg:x="30581" fg:w="141"/><text x="48.8267%" y="158.50"></text></g><g><title>poll (multiprocessing/connection.py:257) (138 samples, 0.22%)</title><rect x="48.5815%" y="164" width="0.2192%" height="15" fill="rgb(231,57,52)" fg:x="30584" fg:w="138"/><text x="48.8315%" y="174.50"></text></g><g><title>_handle_workers (multiprocessing/pool.py:519) (552 samples, 0.88%)</title><rect x="47.9572%" y="116" width="0.8768%" height="15" fill="rgb(248,177,22)" fg:x="30191" fg:w="552"/><text x="48.2072%" y="126.50"></text></g><g><title>_recv (multiprocessing/connection.py:379) (4,825 samples, 7.66%)</title><rect x="48.8881%" y="180" width="7.6643%" height="15" fill="rgb(215,211,37)" fg:x="30777" fg:w="4825"/><text x="49.1381%" y="190.50">_recv (mul..</text></g><g><title>_recv (multiprocessing/connection.py:386) (3,427 samples, 5.44%)</title><rect x="56.5905%" y="180" width="5.4437%" height="15" fill="rgb(241,128,51)" fg:x="35626" fg:w="3427"/><text x="56.8405%" y="190.50">_recv (..</text></g><g><title>get (multiprocessing/queues.py:103) (8,288 samples, 13.17%)</title><rect x="48.8770%" y="132" width="13.1652%" height="15" fill="rgb(227,165,31)" fg:x="30770" fg:w="8288"/><text x="49.1270%" y="142.50">get (multiprocessing..</text></g><g><title>recv_bytes (multiprocessing/connection.py:216) (8,288 samples, 13.17%)</title><rect x="48.8770%" y="148" width="13.1652%" height="15" fill="rgb(228,167,24)" fg:x="30770" fg:w="8288"/><text x="49.1270%" y="158.50">recv_bytes (multipro..</text></g><g><title>_recv_bytes (multiprocessing/connection.py:421) (8,286 samples, 13.16%)</title><rect x="48.8801%" y="164" width="13.1620%" height="15" fill="rgb(228,143,12)" fg:x="30772" fg:w="8286"/><text x="49.1301%" y="174.50">_recv_bytes (multipr..</text></g><g><title>answer_challenge (multiprocessing/connection.py:752) (68 samples, 0.11%)</title><rect x="66.4120%" y="212" width="0.1080%" height="15" fill="rgb(249,149,8)" fg:x="41809" fg:w="68"/><text x="66.6620%" y="222.50"></text></g><g><title>recv_bytes (multiprocessing/connection.py:216) (68 samples, 0.11%)</title><rect x="66.4120%" y="228" width="0.1080%" height="15" fill="rgb(243,35,44)" fg:x="41809" fg:w="68"/><text x="66.6620%" y="238.50"></text></g><g><title>Client (multiprocessing/connection.py:508) (111 samples, 0.18%)</title><rect x="66.4120%" y="196" width="0.1763%" height="15" fill="rgb(246,89,9)" fg:x="41809" fg:w="111"/><text x="66.6620%" y="206.50"></text></g><g><title>Client (multiprocessing/connection.py:509) (107 samples, 0.17%)</title><rect x="66.5883%" y="196" width="0.1700%" height="15" fill="rgb(233,213,13)" fg:x="41920" fg:w="107"/><text x="66.8383%" y="206.50"></text></g><g><title>deliver_challenge (multiprocessing/connection.py:742) (66 samples, 0.10%)</title><rect x="66.6534%" y="212" width="0.1048%" height="15" fill="rgb(233,141,41)" fg:x="41961" fg:w="66"/><text x="66.9034%" y="222.50"></text></g><g><title>send_bytes (multiprocessing/connection.py:200) (66 samples, 0.10%)</title><rect x="66.6534%" y="228" width="0.1048%" height="15" fill="rgb(239,167,4)" fg:x="41961" fg:w="66"/><text x="66.9034%" y="238.50"></text></g><g><title>_send_bytes (multiprocessing/connection.py:411) (66 samples, 0.10%)</title><rect x="66.6534%" y="244" width="0.1048%" height="15" fill="rgb(209,217,16)" fg:x="41961" fg:w="66"/><text x="66.9034%" y="254.50"></text></g><g><title>_send (multiprocessing/connection.py:368) (66 samples, 0.10%)</title><rect x="66.6534%" y="260" width="0.1048%" height="15" fill="rgb(219,88,35)" fg:x="41961" fg:w="66"/><text x="66.9034%" y="270.50"></text></g><g><title>get_connection (multiprocessing/resource_sharer.py:86) (249 samples, 0.40%)</title><rect x="66.3659%" y="180" width="0.3955%" height="15" fill="rgb(220,193,23)" fg:x="41780" fg:w="249"/><text x="66.6159%" y="190.50"></text></g><g><title>detach (multiprocessing/resource_sharer.py:57) (262 samples, 0.42%)</title><rect x="66.3627%" y="164" width="0.4162%" height="15" fill="rgb(230,90,52)" fg:x="41778" fg:w="262"/><text x="66.6127%" y="174.50"></text></g><g><title>rebuild_storage_fd (torch/multiprocessing/reductions.py:307) (319 samples, 0.51%)</title><rect x="66.3612%" y="148" width="0.5067%" height="15" fill="rgb(252,106,19)" fg:x="41777" fg:w="319"/><text x="66.6112%" y="158.50"></text></g><g><title>results_loop (batchgenerators/dataloading/multi_threaded_augmenter.py:101) (11,419 samples, 18.14%)</title><rect x="48.8341%" y="116" width="18.1386%" height="15" fill="rgb(206,74,20)" fg:x="30743" fg:w="11419"/><text x="49.0841%" y="126.50">results_loop (batchgenerator..</text></g><g><title>get (multiprocessing/queues.py:122) (3,104 samples, 4.93%)</title><rect x="62.0421%" y="132" width="4.9306%" height="15" fill="rgb(230,138,44)" fg:x="39058" fg:w="3104"/><text x="62.2921%" y="142.50">get (m..</text></g><g><title>results_loop (batchgenerators/dataloading/multi_threaded_augmenter.py:107) (498 samples, 0.79%)</title><rect x="66.9727%" y="116" width="0.7911%" height="15" fill="rgb(235,182,43)" fg:x="42162" fg:w="498"/><text x="67.2227%" y="126.50"></text></g><g><title>results_loop (batchgenerators/dataloading/multi_threaded_augmenter.py:117) (388 samples, 0.62%)</title><rect x="67.7638%" y="116" width="0.6163%" height="15" fill="rgb(242,16,51)" fg:x="42660" fg:w="388"/><text x="68.0138%" y="126.50"></text></g><g><title>results_loop (batchgenerators/dataloading/multi_threaded_augmenter.py:125) (19,711 samples, 31.31%)</title><rect x="68.3896%" y="116" width="31.3102%" height="15" fill="rgb(248,9,4)" fg:x="43054" fg:w="19711"/><text x="68.6396%" y="126.50">results_loop (batchgenerators/dataloading/multi_thr..</text></g><g><title>run (threading.py:917) (39,789 samples, 63.20%)</title><rect x="36.7776%" y="100" width="63.2033%" height="15" fill="rgb(210,31,22)" fg:x="23153" fg:w="39789"/><text x="37.0276%" y="110.50">run (threading.py:917)</text></g><g><title>results_loop (batchgenerators/dataloading/multi_threaded_augmenter.py:90) (160 samples, 0.25%)</title><rect x="99.7268%" y="116" width="0.2542%" height="15" fill="rgb(239,54,39)" fg:x="62782" fg:w="160"/><text x="99.9768%" y="126.50"></text></g><g><title>&lt;listcomp&gt; (batchgenerators/dataloading/multi_threaded_augmenter.py:90) (155 samples, 0.25%)</title><rect x="99.7347%" y="132" width="0.2462%" height="15" fill="rgb(230,99,41)" fg:x="62787" fg:w="155"/><text x="99.9847%" y="142.50"></text></g><g><title>is_alive (multiprocessing/process.py:165) (139 samples, 0.22%)</title><rect x="99.7601%" y="148" width="0.2208%" height="15" fill="rgb(253,106,12)" fg:x="62803" fg:w="139"/><text x="100.0101%" y="158.50"></text></g><g><title>poll (multiprocessing/popen_fork.py:27) (133 samples, 0.21%)</title><rect x="99.7697%" y="164" width="0.2113%" height="15" fill="rgb(213,46,41)" fg:x="62809" fg:w="133"/><text x="100.0197%" y="174.50"></text></g><g><title>_bootstrap_inner (threading.py:980) (39,801 samples, 63.22%)</title><rect x="36.7761%" y="84" width="63.2224%" height="15" fill="rgb(215,133,35)" fg:x="23152" fg:w="39801"/><text x="37.0261%" y="94.50">_bootstrap_inner (threading.py:980)</text></g><g><title>all (62,954 samples, 100%)</title><rect x="0.0000%" y="52" width="100.0000%" height="15" fill="rgb(213,28,5)" fg:x="0" fg:w="62954"/><text x="0.2500%" y="62.50"></text></g><g><title>_bootstrap (threading.py:937) (39,802 samples, 63.22%)</title><rect x="36.7761%" y="68" width="63.2239%" height="15" fill="rgb(215,77,49)" fg:x="23152" fg:w="39802"/><text x="37.0261%" y="78.50">_bootstrap (threading.py:937)</text></g></svg></svg>